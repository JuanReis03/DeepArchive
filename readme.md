# DeepArchive

**DeepArchive** √© um sistema de busca sem√¢ntica inteligente projetado para aprimorar instrumentos de busca em arquivos permanentes. Este projeto, parte da minha pesquisa cient√≠fica do grupo LTI DIGITAL, utiliza modelos de linguagem de larga escala (LLMs) para ir al√©m da busca tradicional por palavras-chave.

O objetivo √© criar um "servi√ßo de refer√™ncia digital" capaz de compreender o **contexto** e a **inten√ß√£o** por tr√°s de uma consulta, retornando resultados semanticamente relevantes, mesmo que os termos exatos n√£o estejam presentes no documento.

## üíª Tecnologias Utilizadas

* **Python 3.12+**
* **DeepSeek (via Ollama):** O modelo de LLM usado para gerar os *embeddings* (representa√ß√µes vetoriais) dos textos.
* **Ollama:** Ferramenta para servir e gerenciar os modelos LLM localmente.
* **LangChain:** O framework principal para construir o *pipeline* de processamento (carregar, dividir, indexar, consultar).
* **ChromaDB:** O banco de dados vetorial de c√≥digo aberto usado para armazenar e consultar os *embeddings*.

## üöÄ Status Atual (Fase 1 - Conclu√≠da)

O *pipeline* central do DeepArchive est√° 100% funcional. O que j√° foi implementado:

* **Indexa√ß√£o de Documentos (`index.py`):**
    * Carregamento autom√°tico de todos os arquivos `.pdf` da pasta `/data`.
    * Fragmenta√ß√£o (*chunking*) dos textos em segmentos otimizados.
    * Gera√ß√£o de *embeddings* usando o modelo **DeepSeek (`deepseek-llm`)** servido localmente via Ollama.
    * Persist√™ncia dos vetores em um banco de dados **ChromaDB** local (na pasta `/db`).

* **Consulta Sem√¢ntica (`query.py`):**
    * Um script de console interativo que recebe perguntas do usu√°rio.
    * Gera√ß√£o de *embedding* para a consulta usando o mesmo modelo DeepSeek (garantindo consist√™ncia).
    * Realiza√ß√£o da busca por similaridade (k=3) no ChromaDB, retornando os *chunks* de texto mais relevantes.
    * Exibi√ß√£o dos resultados com o conte√∫do e a fonte (nome do arquivo e p√°gina).

## ‚öôÔ∏è Como Executar o Projeto

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [URL-DO-SEU-REPOSIT√ìRIO]
    cd busca-de-arquivos-IC
    ```

2.  **Instale o Ollama:**
    * Baixe e instale o [Ollama](https://ollama.com/) no seu sistema.
    * Puxe o modelo DeepSeek que ser√° usado:
        ```bash
        ollama pull deepseek-llm
        ```

3.  **Crie e ative o ambiente virtual (venv):**
    ```bash
    python -m venv venv
    .\venv\Scripts\activate
    ```
    *(No Linux/Mac: `source venv/bin/activate`)*

4.  **Instale as depend√™ncias:**
    ```bash
    # Primeiro, PyTorch com suporte a CUDA
    pip install torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/cu121](https://download.pytorch.org/whl/cu121)
    
    # Depois, as bibliotecas do projeto
    pip install -U langchain langchain-community pypdf langchain-chroma langchain-ollama
    ```

5.  **Adicione seus arquivos:**
    * Coloque os arquivos `.pdf` que deseja indexar dentro da pasta `/data`.

6.  **Execute a Indexa√ß√£o (Apenas uma vez):**
    * Este script processar√° os arquivos da pasta `/data` e criar√° o banco `db`.
        ```bash
        python index.py
        ```

7.  **Execute a Consulta:**
    * Inicie o script de busca interativo.
        ```bash
        python query.py
        ```

## üó∫Ô∏è Planos Futuros (Roadmap)

O *pipeline* atual √© a funda√ß√£o. Os pr√≥ximos passos focam em expandir as funcionalidades, a usabilidade e a robustez do sistema, conforme delineado no documento da pesquisa:

* **Melhorias na Ingest√£o de Dados:**
    * Adicionar suporte a m√∫ltiplos formatos de arquivo (`.txt`, `.docx`, `.md`).
    * Implementar OCR para extrair texto de PDFs baseados em imagem (scans).

* **Melhorias na Interface (UX):**
    * **[Prototipagem R√°pida]** Substituir o `query.py` por uma interface web usando **Streamlit**.
    * Agrupar resultados da busca por arquivo de origem, exibindo as p√°ginas relevantes (ex: "Arquivo X: p√°gs 2, 5, 10").

* **Melhorias na IA ("C√©rebro"):**
    * **[RAG]** Fazer com que o sistema **responda** √†s perguntas usando os *chunks* como contexto (Retrieval-Augmented Generation), em vez de apenas mostrar os *chunks*.
    * Implementar **filtragem por metadados** (ex: buscar "IA Generativa" APENAS em documentos de 2024).

* **N√≠vel de Produ√ß√£o (Deploy):**
    * **[Containeriza√ß√£o]** Criar um `Dockerfile` e `docker-compose.yml` para empacotar a aplica√ß√£o, facilitando o deploy.
    * Estabelecer um *pipeline* de avalia√ß√£o para medir a qualidade (precis√£o e *recall*) das respostas do sistema.