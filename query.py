import sys
import time  # Importante para contar o tempo
# --- Importa√ß√µes de IA e Banco de Dados ---
from langchain_ollama.embeddings import OllamaEmbeddings
from langchain_chroma import Chroma
from langchain_ollama import ChatOllama

# --- Importa√ß√µes de Busca (Retrievers) ---
from langchain_classic.retrievers import EnsembleRetriever  
from langchain_community.retrievers import BM25Retriever

# --- Importa√ß√µes do Core do LangChain ---
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# --- Defini√ß√µes ---
DB_PATH = 'db'
MODEL_NAME = "deepseek-llm"      # Modelo para Embeddings
LLM_MODEL = "deepseek-llm"   # Modelo para o Chat

print("--- Inicializando o DeepArchive (Modo RAG com Metadados) ---")

# 1. Carregar Embedding e Banco Vetorial
print("1. Carregando mem√≥ria vetorial...")
embeddings = OllamaEmbeddings(model=MODEL_NAME)
vectorstore = Chroma(persist_directory=DB_PATH, embedding_function=embeddings)

# 2. Configurar Busca H√≠brida (BM25 + Chroma)
print("2. Indexando palavras-chave (BM25) em mem√≥ria...")
data = vectorstore.get()
# Recria objetos Document para o BM25
doc_objects = [Document(page_content=c, metadata=m) for c, m in zip(data['documents'], data['metadatas'])]

if not doc_objects:
    print("ERRO: O banco de dados est√° vazio! Rode o 'index.py' primeiro.")
    sys.exit()

bm25_retriever = BM25Retriever.from_documents(doc_objects)
bm25_retriever.k = 5  # Top 5 por palavra-chave

chroma_retriever = vectorstore.as_retriever(search_kwargs={"k": 5}) # Top 5 por sem√¢ntica

ensemble_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, chroma_retriever],
    weights=[0.5, 0.5] # 50% peso para cada m√©todo
)

# 3. Configurar o C√©rebro (LLM)
print(f"3. Conectando ao modelo de chat ({LLM_MODEL})...")
llm = ChatOllama(model=LLM_MODEL)

# 4. O Prompt
template = """Voc√™ √© um assistente de pesquisa acad√™mica chamado DeepArchive.
Use APENAS os contextos fornecidos abaixo para responder √† pergunta do usu√°rio.
Se a resposta n√£o estiver nos contextos, diga que n√£o sabe. N√£o invente informa√ß√µes.
Cite o nome dos arquivos fonte sempre que poss√≠vel no corpo do texto.

Contextos:
{context}

Pergunta: {question}

Resposta:"""

prompt = ChatPromptTemplate.from_template(template)

# Fun√ß√£o auxiliar para limpar nomes de arquivos
def clean_source_name(source_path):
    if "\\" in source_path: return source_path.split("\\")[-1]
    elif "/" in source_path: return source_path.split("/")[-1]
    return source_path

# Fun√ß√£o para formatar os documentos em uma string √∫nica
def format_docs(docs):
    formatted_docs = []
    for doc in docs:
        source = doc.metadata.get('source', 'Desconhecido')
        clean_name = clean_source_name(source)
        formatted_docs.append(f"[Fonte: {clean_name}]:\n{doc.page_content}")
    return "\n\n".join(formatted_docs)

# 5. Criar a "Corrente" APENAS de Gera√ß√£o (A recupera√ß√£o faremos manualmente no loop)
generation_chain = (
    prompt
    | llm
    | StrOutputParser()
)

print("\n--- Sistema Pronto! Pergunte sobre seus documentos. Digite 'sair' para encerrar ---")


# 6. Loop de Conversa - RAG
while True:
    query = input("\nVoc√™: ")
    if query.lower() in ['sair', 'exit', 'quit']:
        break
    
    if not query.strip():
        continue

    # Inicia a contagem do tempo
    start_time = time.time()

    print("\nDeepArchive buscando fontes...", end="", flush=True)
    
    # --- Passo A: Recuperar Documentos (Manual) ---
    retrieved_docs = ensemble_retriever.invoke(query)
    
    # --- Passo B: Extrair Fontes ---
    unique_sources = set() # Usamos um set para n√£o repetir nomes
    for doc in retrieved_docs:
        raw_source = doc.metadata.get('source', 'Desconhecido')
        unique_sources.add(clean_source_name(raw_source))
    
    # --- Passo C: Formatar Contexto ---
    context_text = format_docs(retrieved_docs)

    print("\rDeepArchive gerando resposta... ", end="") 
    
    # --- Passo D: Gerar Resposta ---
    try:
        # Passamos o contexto j√° formatado e a pergunta
        for chunk in generation_chain.stream({"context": context_text, "question": query}):
            print(chunk, end="", flush=True)
        print("\n")
        
        # --- Passo E: Exibir Estat√≠sticas ---
        end_time = time.time()
        elapsed_time = end_time - start_time
        
        # Formata o tempo (se for menos de 60s mostra segundos, se for mais, mostra min:seg)
        if elapsed_time < 60:
            time_str = f"{elapsed_time:.2f} segundos"
        else:
            minutes = int(elapsed_time // 60)
            seconds = int(elapsed_time % 60)
            time_str = f"{minutes}m {seconds}s"

        print("-" * 50)
        print(f"‚è±Ô∏è  Tempo total: {time_str}")
        print(f"üìÇ Fontes consultadas: {', '.join(unique_sources)}")
        print("-" * 50)

    except Exception as e:
        print(f"\nOcorreu um erro na gera√ß√£o: {e}")

           
# ==============================================================================
# üî¥ MODO RAG / CHAT (DESATIVADO) - Tire os '"""' abaixo para desativar a IA
# ==============================================================================
"""      
# 6. Loop de Conversa - Padr√£o
while True:
    query = input("\nVoc√™: ")
    if query.lower() in ['sair', 'exit', 'quit']:
        break
    
    if not query.strip():
        continue

    # Inicia a contagem do tempo
    start_time = time.time()

    print("\nDeepArchive buscando fontes...", end="", flush=True)
    
    # --- Passo A: Recuperar Documentos (MANTENHA ISSO) ---
    retrieved_docs = ensemble_retriever.invoke(query)
    
    # ==============================================================================
    # üü¢ MODO BUSCA SIMPLES (ATIVO) - Use isso para mostrar apenas os documentos
    # ==============================================================================
    print(f"\n\n--- üîé Encontrei {len(retrieved_docs)} documentos relevantes: ---\n")
    
    for i, doc in enumerate(retrieved_docs):
        # Limpa o nome do arquivo usando sua fun√ß√£o auxiliar ou split direto
        raw_source = doc.metadata.get('source', 'Desconhecido')
        if "\\" in raw_source: clean_name = raw_source.split("\\")[-1]
        elif "/" in raw_source: clean_name = raw_source.split("/")[-1]
        else: clean_name = raw_source
        
        # Mostra o resultado
        print(f"[Resultado {i+1}] üìÇ Arquivo: {clean_name}")
        # Mostra os primeiros 300 caracteres do conte√∫do
        print(f"üìÑ Trecho: \"{doc.page_content[:300].replace(chr(10), ' ')}...\"") 
        print("-" * 50)
    
    # Exibir estat√≠sticas de tempo apenas
    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"‚è±Ô∏è  Tempo de busca: {elapsed_time:.2f} segundos")
    
    """
